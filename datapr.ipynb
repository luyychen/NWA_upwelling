{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "file_path = os.path.expandvars('$WORK/data/OISST/monthly/sst.mon.mean.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "\n",
    "[xmin,xmax,ymin,ymax]=[330,355,10,35]\n",
    "[tmin,tmax]=[\"1993\",\"2022\"]\n",
    "sst=ds['sst'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax),time=slice(tmin,tmax)).values\n",
    "sst0=ds['sst'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax)).isel(time=0).values\n",
    "\n",
    "lon=ds['lon'].sel(lon=slice(xmin, xmax)).values\n",
    "lat=ds['lat'].sel(lat=slice(ymin,ymax)).values\n",
    "time=ds['time'].sel(time=slice(tmin,tmax))\n",
    "\n",
    "\n",
    "    \n",
    "coast = {'lat': [], 'lon': []}\n",
    "    \n",
    "for i, lat_val in enumerate(lat):\n",
    "    for j, lon_val in enumerate(lon):            \n",
    "        if np.isnan(sst0[i, j]):\n",
    "            coast['lat'].append(lat_val.item())\n",
    "            coast['lon'].append(lon_val.item())\n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sstu\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'sstu_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind ekman transport and pumping\n",
    "import glob\n",
    "\n",
    "data_dir = os.path.expandvars('$WORK/data/CCMP/monthly/')\n",
    "file_pattern = os.path.join(data_dir, 'CCMP_Wind_Analysis_??????_monthly_mean_V03.1_L4.nc')\n",
    "file_list = sorted(glob.glob(file_pattern))\n",
    "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "u=ds['u'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin,ymax),time=slice(tmin,tmax)).values\n",
    "v=ds['v'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin,ymax),time=slice(tmin,tmax)).values\n",
    "\n",
    "n = 8\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "uc = np.empty((u.shape[0],len(coast['lat']), n))\n",
    "vc = np.empty((v.shape[0],len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    uc[:, point_idx, :] = u[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    vc[:, point_idx, :] = v[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "uc[np.abs(uc) > 100] = np.nan\n",
    "vc[np.abs(vc) > 100] = np.nan\n",
    "\n",
    "# alongshore wind\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "    \n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    x = delta_lon * np.cos((lat1_rad + lat2_rad) / 2)\n",
    "    y = delta_lat\n",
    "    \n",
    "    bearing_rad = np.arctan2(y, x)\n",
    "    bearing_deg = np.rad2deg(bearing_rad)\n",
    "    bearing_deg = (bearing_deg + 360) % 360\n",
    "    \n",
    "    return bearing_deg\n",
    "\n",
    "point_num = len(coast['lat'])\n",
    "coast_orientation = np.empty(point_num)\n",
    "\n",
    "for i in range(point_num):\n",
    "    if i < point_num - 1:\n",
    "        lat1 = coast['lat'][i]\n",
    "        lon1 = coast['lon'][i]\n",
    "        lat2 = coast['lat'][i+1]\n",
    "        lon2 = coast['lon'][i+1]\n",
    "    else:\n",
    "        lat1 = coast['lat'][i-1]\n",
    "        lon1 = coast['lon'][i-1]\n",
    "        lat2 = coast['lat'][i]\n",
    "        lon2 = coast['lon'][i]\n",
    "    \n",
    "    bearing = calculate_bearing(lat1, lon1, lat2, lon2)\n",
    "    coast_orientation[i] = bearing\n",
    "\n",
    "coast_orientation_rad = np.deg2rad(coast_orientation)\n",
    "u_alongshore = np.cos(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "v_alongshore = np.sin(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "wind_alongshore = uc * u_alongshore + vc * v_alongshore\n",
    "\n",
    "# Define the haversine function\n",
    "coast_lon = np.array(coast['lon'])  # Shape: (100,)\n",
    "coast_lat = np.array(coast['lat'])  # Shape: (100,)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  \n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "\n",
    "    # Compute differences\n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(delta_lat / 2.0) ** 2 + \\\n",
    "        np.cos(lat1_rad) * np.cos(lat2_rad) * \\\n",
    "        np.sin(delta_lon / 2.0) ** 2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Expand coast_lon and coast_lat for broadcasting\n",
    "coast_lon_expanded = coast_lon[:, np.newaxis]  # Shape: (100, 1)\n",
    "coast_lat_expanded = coast_lat[:, np.newaxis]  # Shape: (100, 1)\n",
    "\n",
    "# Compute distances\n",
    "distances = haversine(coast_lat_expanded, coast_lon_expanded, latc, lonc)  # Shape: (100, 8)\n",
    "\n",
    "# Constants\n",
    "rhoa = 1.22  # air density (kg/m^3)\n",
    "cd = 0.0013  # drag coefficient\n",
    "rho = 1025  # water density (kg/m^3)\n",
    "omega = 7.2921e-5  # Earth's rotation rate (rad/s)\n",
    "\n",
    "f = 2 * omega * np.sin(latc* np.pi / 180)\n",
    "\n",
    "# Calculate magnitude of horizontal velocity\n",
    "windspeed = np.sqrt(uc**2 + vc**2)\n",
    "\n",
    "# Ekman transport calculation\n",
    "etransport = -rhoa * cd * windspeed * wind_alongshore / (rho * f * distances)\n",
    "\n",
    "\n",
    "epumping = np.zeros_like(uc)  # Ensure it has the right shape and is mutable\n",
    "dy = 111000.0 * (lat[1] - lat[0])  # scalar\n",
    "dv_dx = np.zeros_like(uc)\n",
    "for j in range(lat.shape[0]):\n",
    "    x_j = 111000.0 * np.cos(np.radians(lat[j])) * (lon[1] - lon[0]) \n",
    "    epumping[:,j,:] = (rhoa * cd * windspeed[:,j,:] / (rho)) * (np.gradient(vc[:, j, :]/f[j], x_j, axis=-1) - np.gradient(uc[:,j,:]/f[j], dy, axis=1))\n",
    "\n",
    "np.savez(f'ekman_{tmin}_{tmax}.npz', etransport=etransport, epumping=epumping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sla\n",
    "import glob\n",
    "\n",
    "# Path template\n",
    "data_dir = os.path.expandvars('$WORK/data/SSH/monthly/????/')\n",
    "file_pattern = os.path.join(data_dir, 'dt_global_allsat_msla_h_y????_m??.nc')\n",
    "file_list = sorted(glob.glob(file_pattern))\n",
    "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "sla=ds['sla'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin,ymax),time=slice(tmin,tmax)).values\n",
    "\n",
    "n = 8\n",
    "slac = np.empty((sla.shape[0],len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    slac[:, point_idx, :] = sla[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "slacm=np.nanmean(slac,axis=0)  \n",
    "slac -= slacm\n",
    "np.savez(f'slac_{tmin}_{tmax}.npz', slac=slac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chl\n",
    "file_path = os.path.expandvars('$WORK/data/GlobColour/monthly/cmems_obs-oc_glo_bgc-plankton_my_l4-multi-4km_P1M_CHL_1997-09-01-2024-08-01.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['longitude'] = (ds['longitude'] + 360) % 360\n",
    "ds=ds.sortby('longitude')\n",
    "CHL=ds['CHL'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin,ymax),time=slice(\"1998\",tmax))\n",
    "CHL=CHL.interpolate_na(dim=\"longitude\", method=\"nearest\")\n",
    "CHL=CHL.interpolate_na(dim=\"latitude\", method=\"nearest\")\n",
    "CHL=CHL.bfill(dim=\"longitude\").bfill(dim=\"latitude\")\n",
    "CHL=CHL.ffill(dim=\"longitude\").ffill(dim=\"latitude\")\n",
    "lat_xr = xr.DataArray(lat, dims=\"latitude\")\n",
    "lon_xr = xr.DataArray(lon, dims=\"longitude\")\n",
    "chl = CHL.interp(latitude=lat_xr, longitude=lon_xr).values\n",
    "\n",
    "\n",
    "n = 16\n",
    "chlc = np.empty((chl.shape[0],len(coast['lat']), n))\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    chlc[:, point_idx, :] = chl[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "np.savez(f'chlc_1998_{tmax}.npz', chlc=chlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(chlc).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mld\n",
    "import glob\n",
    "\n",
    "data_dir = os.path.expandvars('$WORK/data/ARMOR/monthly/????/')\n",
    "file_pattern = os.path.join(data_dir, 'dataset-armor-3d-rep-monthly_????????T????Z_P????????T????Z.nc')\n",
    "file_list = sorted(glob.glob(file_pattern))\n",
    "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "ds['longitude'] = (ds['longitude'] + 360) % 360\n",
    "ds=ds.sortby('longitude')\n",
    "MLD=ds['mlotst'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin,ymax),time=slice(tmin,tmax))\n",
    "lat_xr = xr.DataArray(lat, dims=\"latitude\")\n",
    "lon_xr = xr.DataArray(lon, dims=\"longitude\")\n",
    "mld = MLD.interp(latitude=lat_xr, longitude=lon_xr).values\n",
    "\n",
    "n = 16\n",
    "mldc = np.empty((mld.shape[0],len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    mldc[:, point_idx, :] = mld[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "np.savez(f'mldc_{tmin}_{tmax}.npz', mldc=mldc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate ww\n",
    "dy = 0.25 * 111320  # meters (constant)\n",
    "dz = 70  # meters\n",
    "\n",
    "def compute_ww(uu, vv, lats, dx_base=0.25 * 111320, dy=dy, dz=dz):\n",
    "    # Convert latitude to radians\n",
    "    lats_rad = np.radians(lats)\n",
    "    \n",
    "    # Compute dx for each latitude\n",
    "    dx = dx_base * np.cos(lats_rad)  # meters\n",
    "\n",
    "    # Expand dx to match (time, lon, lat) shape\n",
    "    dx = dx[np.newaxis, np.newaxis, :]  # Shape (1, 1, lat)\n",
    "\n",
    "    # Compute derivatives using central differences (ignoring edges)\n",
    "    dudx = (uu[:, 2:, 1:-1] - uu[:, :-2, 1:-1]) / (2 * dx[:, :, 1:-1])\n",
    "    dvdy = (vv[:, 1:-1, 2:] - vv[:, 1:-1, :-2]) / (2 * dy)\n",
    "\n",
    "    # Compute ww using continuity equation\n",
    "    ww = dz * (dudx + dvdy)\n",
    "\n",
    "    # Pad the result to match original shape (setting edges to NaN)\n",
    "    ww_full = np.full_like(uu, np.nan)\n",
    "    ww_full[:, 1:-1, 1:-1] = ww\n",
    "\n",
    "    return ww_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSCAR no interp\n",
    "file_path = os.path.expandvars('$WORK/data/OSCAR/oscar_monthly_mean_1993_2022.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds = ds.where(\n",
    "    (ds.lat >= ymin) & (ds.lat <= ymax) & \n",
    "    (ds.lon >= xmin) & (ds.lon <= xmax), \n",
    "    drop=True\n",
    ")\n",
    "u=ds['u']\n",
    "v=ds['v']\n",
    "ug=ds['ug']\n",
    "vg=ds['vg']\n",
    "u0=ds['u'].isel(time=0).interpolate_na(dim=\"longitude\", method=\"linear\")\n",
    "\n",
    "uu = np.swapaxes(u.values, 1, 2)  # swapaxes to (time,lat,lon)\n",
    "vv = np.swapaxes(v.values, 1, 2)\n",
    "ug = np.swapaxes(ug.values, 1, 2)\n",
    "vg = np.swapaxes(vg.values, 1, 2)\n",
    "uu0 = np.swapaxes(np.squeeze(u0.values), 0, 1)  # swapaxes to (time,lat,lon)\n",
    "\n",
    "lon=ds['lon'].values\n",
    "lat=ds['lat'].values\n",
    "time=ds['time']\n",
    "\n",
    "# fill nan values to 0\n",
    "uu[np.isnan(uu)] = 0\n",
    "vv[np.isnan(vv)] = 0\n",
    "ug[np.isnan(ug)] = 0\n",
    "vg[np.isnan(vg)] = 0\n",
    "\n",
    "ww = compute_ww(uu, vv, lat)\n",
    "wg = compute_ww(ug, vg, lat)\n",
    "    \n",
    "coast = {'lat': [], 'lon': []}\n",
    "    \n",
    "for i, lat_val in enumerate(lat):\n",
    "    for j, lon_val in enumerate(lon):            \n",
    "        if np.isnan(uu0[i, j]):\n",
    "            coast['lat'].append(lat_val.item())\n",
    "            coast['lon'].append(lon_val.item())\n",
    "            break  \n",
    "\n",
    "n = 16  # coast band + ocean band\n",
    "uc = np.empty((uu.shape[0],len(coast['lat']), n))\n",
    "vc = np.empty((vv.shape[0],len(coast['lat']), n))\n",
    "wc = np.empty((ww.shape[0],len(coast['lat']), n))\n",
    "wgc = np.empty((wg.shape[0],len(coast['lat']), n))\n",
    "\n",
    "lono = np.empty((len(coast['lat']), n))\n",
    "lato = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    uc[:, point_idx, :] = uu[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    vc[:, point_idx, :] = vv[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    wc[:, point_idx, :] = ww[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    wgc[:, point_idx, :] = wg[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lono[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    lato[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "#uc[np.abs(uc) > 100] = np.nan\n",
    "#vc[np.abs(vc) > 100] = np.nan\n",
    "\n",
    "# alongshore wind\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "    \n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    x = delta_lon * np.cos((lat1_rad + lat2_rad) / 2)\n",
    "    y = delta_lat\n",
    "    \n",
    "    bearing_rad = np.arctan2(y, x)\n",
    "    bearing_deg = np.rad2deg(bearing_rad)\n",
    "    bearing_deg = (bearing_deg + 360) % 360\n",
    "    \n",
    "    return bearing_deg\n",
    "\n",
    "point_num = len(coast['lat'])\n",
    "coast_orientation = np.empty(point_num)\n",
    "\n",
    "for i in range(point_num):\n",
    "    if i < point_num - 1:\n",
    "        lat1 = coast['lat'][i]\n",
    "        lon1 = coast['lon'][i]\n",
    "        lat2 = coast['lat'][i+1]\n",
    "        lon2 = coast['lon'][i+1]\n",
    "    else:\n",
    "        lat1 = coast['lat'][i-1]\n",
    "        lon1 = coast['lon'][i-1]\n",
    "        lat2 = coast['lat'][i]\n",
    "        lon2 = coast['lon'][i]\n",
    "    \n",
    "    bearing = calculate_bearing(lat1, lon1, lat2, lon2)\n",
    "    coast_orientation[i] = bearing\n",
    "\n",
    "coast_orientation_rad = np.deg2rad(coast_orientation)\n",
    "u_alongshore = np.cos(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "v_alongshore = np.sin(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "current_alongshore = uc * u_alongshore + vc * v_alongshore\n",
    "np.savez(f'oscar_nointerp_{tmin}_{tmax}.npz', current_alongshore=current_alongshore, uc=uc, vc=vc, wc=wc, wgc=wgc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hfxc\n",
    "import glob\n",
    "\n",
    "data_dir = os.path.expandvars('$WORK/data/Tropflux/monthly')\n",
    "file_pattern = os.path.join(data_dir, 'netflux_tropflux_1m_????.nc')\n",
    "file_list = sorted(glob.glob(file_pattern))\n",
    "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "netflux=ds['netflux'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin-1,ymax),time=slice(tmin,tmax))\n",
    "netflux=netflux.interpolate_na(dim=\"longitude\", method=\"nearest\")\n",
    "netflux=netflux.interpolate_na(dim=\"latitude\", method=\"nearest\")\n",
    "netflux=netflux.bfill(dim=\"longitude\")\n",
    "netflux=netflux.bfill(dim=\"latitude\")\n",
    "lat_xr = xr.DataArray(lat, dims=\"latitude\")\n",
    "lon_xr = xr.DataArray(lon, dims=\"longitude\")\n",
    "hflx = netflux.interp(latitude=lat_xr, longitude=lon_xr).values\n",
    "\n",
    "n = 16\n",
    "hflxc = np.empty((hflx.shape[0],len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    hflxc[:, point_idx, :] = hflx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "hflxu=hflxc[:,:,8:]-hflxc[:,:,:8]\n",
    "np.savez(f'hflx_{tmin}_2018.npz', hflxc=hflxc, hflxu=hflxu, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swr\n",
    "import glob\n",
    "\n",
    "data_dir = os.path.expandvars('$WORK/data/Tropflux/monthly')\n",
    "file_pattern = os.path.join(data_dir, 'swr_tropflux_1m_????.nc')\n",
    "file_list = sorted(glob.glob(file_pattern))\n",
    "ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "netflux=ds['swr'].sel(longitude=slice(xmin,xmax), latitude=slice(ymin-2,ymax),time=slice(tmin,tmax))\n",
    "netflux=netflux.interpolate_na(dim=\"longitude\", method=\"nearest\")\n",
    "netflux=netflux.interpolate_na(dim=\"latitude\", method=\"nearest\")\n",
    "netflux=netflux.bfill(dim=\"longitude\")\n",
    "netflux=netflux.bfill(dim=\"latitude\")\n",
    "lat_xr = xr.DataArray(lat, dims=\"latitude\")\n",
    "lon_xr = xr.DataArray(lon, dims=\"longitude\")\n",
    "hflx = netflux.interp(latitude=lat_xr, longitude=lon_xr).values\n",
    "\n",
    "n = 16\n",
    "hflxc = np.empty((hflx.shape[0],len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    hflxc[:, point_idx, :] = hflx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "hflxu=hflxc[:,:,8:]-hflxc[:,:,:8]\n",
    "np.savez(f'swr_{tmin}_2018.npz', swrc=hflxc, hflxu=hflxu, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fesom-core2-fjra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_budget core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_budget_mld1_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "advx=ds['heat_advx'].groupby('time.month').mean(dim='time').values\n",
    "advy=ds['heat_advy'].groupby('time.month').mean(dim='time').values\n",
    "advz=ds['heat_advz'].groupby('time.month').mean(dim='time').values\n",
    "diffv=ds['heat_diffv'].groupby('time.month').mean(dim='time').values\n",
    "sbc=ds['heat_sbc'].groupby('time.month').mean(dim='time').values\n",
    "tdc=ds['heat_tdc'].groupby('time.month').mean(dim='time').values\n",
    "\n",
    "# also calculate the std and save it\n",
    "advx_std=ds['heat_advx'].groupby('time.month').std(dim='time').values\n",
    "advy_std=ds['heat_advy'].groupby('time.month').std(dim='time').values\n",
    "advz_std=ds['heat_advz'].groupby('time.month').std(dim='time').values\n",
    "diffv_std=ds['heat_diffv'].groupby('time.month').std(dim='time').values\n",
    "sbc_std=ds['heat_sbc'].groupby('time.month').std(dim='time').values\n",
    "tdc_std=ds['heat_tdc'].groupby('time.month').std(dim='time').values\n",
    "\n",
    "n = 16  # coast band + ocean band\n",
    "\n",
    "advx_c = np.empty((advx.shape[0], len(coast['lat']), n))\n",
    "advy_c = np.empty((advy.shape[0], len(coast['lat']), n))\n",
    "advz_c = np.empty((advz.shape[0], len(coast['lat']), n))\n",
    "diffv_c = np.empty((diffv.shape[0], len(coast['lat']), n))\n",
    "sbc_c = np.empty((sbc.shape[0], len(coast['lat']), n))\n",
    "tdc_c = np.empty((tdc.shape[0], len(coast['lat']), n))\n",
    "\n",
    "advx_c_std = np.empty((advx_std.shape[0], len(coast['lat']), n))\n",
    "advy_c_std = np.empty((advy_std.shape[0], len(coast['lat']), n))\n",
    "advz_c_std = np.empty((advz_std.shape[0], len(coast['lat']), n))\n",
    "diffv_c_std = np.empty((diffv_std.shape[0], len(coast['lat']), n))\n",
    "sbc_c_std = np.empty((sbc_std.shape[0], len(coast['lat']), n))\n",
    "tdc_c_std = np.empty((tdc_std.shape[0], len(coast['lat']), n))\n",
    "\n",
    "lono = np.empty((len(coast['lat']), n))\n",
    "lato = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    advx_c[:, point_idx, :] = advx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c[:, point_idx, :] = advy[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c[:, point_idx, :] = advz[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c[:, point_idx, :] = diffv[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c[:, point_idx, :] = sbc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c[:, point_idx, :] = tdc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advx_c_std[:, point_idx, :] = advx_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c_std[:, point_idx, :] = advy_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c_std[:, point_idx, :] = advz_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c_std[:, point_idx, :] = diffv_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c_std[:, point_idx, :] = sbc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c_std[:, point_idx, :] = tdc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lono[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    lato[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "np.savez(f'heat_budget_mld1_fjra_{tmin}_{tmax}.npz',\n",
    "         advx_c=advx_c, advy_c=advy_c, advz_c=advz_c,\n",
    "         diffv_c=diffv_c, sbc_c=sbc_c, tdc_c=tdc_c,\n",
    "         advx_c_std=advx_c_std, advy_c_std=advy_c_std, advz_c_std=advz_c_std,\n",
    "         diffv_c_std=diffv_c_std, sbc_c_std=sbc_c_std, tdc_c_std=tdc_c_std,\n",
    "         lono=lono, lato=lato)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_oce2d_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "sst=ds['sst'].values\n",
    "\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fjra_sstu_m_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_forcing_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "n = 8\n",
    "u = ds['tx_sur'].values\n",
    "v = ds['ty_sur'].values\n",
    "\n",
    "uc = np.empty((u.shape[0],len(coast['lat']), n))\n",
    "vc = np.empty((v.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    uc[:, point_idx, :] = u[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    vc[:, point_idx, :] = v[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "# alongshore wind\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "    \n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    x = delta_lon * np.cos((lat1_rad + lat2_rad) / 2)\n",
    "    y = delta_lat\n",
    "    \n",
    "    bearing_rad = np.arctan2(y, x)\n",
    "    bearing_deg = np.rad2deg(bearing_rad)\n",
    "    bearing_deg = (bearing_deg + 360) % 360\n",
    "    \n",
    "    return bearing_deg\n",
    "\n",
    "point_num = len(coast['lat'])\n",
    "coast_orientation = np.empty(point_num)\n",
    "\n",
    "for i in range(point_num):\n",
    "    if i < point_num - 1:\n",
    "        lat1 = coast['lat'][i]\n",
    "        lon1 = coast['lon'][i]\n",
    "        lat2 = coast['lat'][i+1]\n",
    "        lon2 = coast['lon'][i+1]\n",
    "    else:\n",
    "        lat1 = coast['lat'][i-1]\n",
    "        lon1 = coast['lon'][i-1]\n",
    "        lat2 = coast['lat'][i]\n",
    "        lon2 = coast['lon'][i]\n",
    "    \n",
    "    bearing = calculate_bearing(lat1, lon1, lat2, lon2)\n",
    "    coast_orientation[i] = bearing\n",
    "\n",
    "coast_orientation_rad = np.deg2rad(coast_orientation)\n",
    "u_alongshore = np.cos(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "v_alongshore = np.sin(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "wind_alongshore = uc * u_alongshore + vc * v_alongshore\n",
    "\n",
    "# Define the haversine function\n",
    "coast_lon = np.array(coast['lon'])  # Shape: (100,)\n",
    "coast_lat = np.array(coast['lat'])  # Shape: (100,)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  \n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "\n",
    "    # Compute differences\n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(delta_lat / 2.0) ** 2 + \\\n",
    "        np.cos(lat1_rad) * np.cos(lat2_rad) * \\\n",
    "        np.sin(delta_lon / 2.0) ** 2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Expand coast_lon and coast_lat for broadcasting\n",
    "coast_lon_expanded = coast_lon[:, np.newaxis]  # Shape: (100, 1)\n",
    "coast_lat_expanded = coast_lat[:, np.newaxis]  # Shape: (100, 1)\n",
    "\n",
    "# Compute distances\n",
    "distances = haversine(coast_lat_expanded, coast_lon_expanded, latc, lonc)  # Shape: (100, 8)\n",
    "\n",
    "# Constants\n",
    "rhoa = 1.22  # air density (kg/m^3)\n",
    "cd = 0.0013  # drag coefficient\n",
    "rho = 1025  # water density (kg/m^3)\n",
    "omega = 7.2921e-5  # Earth's rotation rate (rad/s)\n",
    "\n",
    "f = 2 * omega * np.sin(latc* np.pi / 180)\n",
    "\n",
    "# Calculate magnitude of horizontal velocity\n",
    "windspeed = np.sqrt(uc**2 + vc**2)\n",
    "\n",
    "# Ekman transport calculation\n",
    "etransport = -wind_alongshore / (rho * f * distances)\n",
    "# wind_alongshore_mean = wind_alongshore[:, :, 0]\n",
    "# mwind_alongshore_mean_filled = np.broadcast_to(wind_alongshore_mean[:, :, np.newaxis], wind_alongshore.shape)\n",
    "# etransport = -wind_alongshore_mean_filled / (rho * f * distances)\n",
    "\n",
    "epumping = np.zeros_like(uc)  # Ensure it has the right shape and is mutable\n",
    "dy = 111000.0 * (lat[1] - lat[0])  # scalar\n",
    "dv_dx = np.zeros_like(uc)\n",
    "for j in range(lat.shape[0]):\n",
    "    x_j = 111000.0 * np.cos(np.radians(lat[j])) * (lon[1] - lon[0]) \n",
    "    epumping[:,j,:] = 1 / (rho ) * (np.gradient(vc[:, j, :]/ f[j], x_j, axis=-1) - np.gradient(uc[:,j,:]/ f[j], dy, axis=1))\n",
    "\n",
    "np.savez(f'fesom_core2_fjra_ekman_m_{tmin}_{tmax}.npz', windspeed=windspeed, etransport=etransport, epumping=epumping, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_forcing_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "fh=-ds['fh'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "fhc = np.empty((fh.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    fhc[:, point_idx, :] = fh[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "fh=fhc[:,:,8:]-fhc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fjra_fh_m_{tmin}_{tmax}.npz', fh=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_w_mld1_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "w=ds['w_mld'].groupby('time.month').mean(dim='time').values\n",
    "n = 8\n",
    "wc = np.empty((w.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    wc[:, point_idx, :] = w[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "np.savez(f'fesom_core2_fjra_w_mld1_m_{tmin}_{tmax}.npz', wc=wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_oce2d_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "mld=-ds['MLD1'].groupby('time.month').mean(dim='time').values\n",
    "\n",
    "\n",
    "\n",
    "n = 16\n",
    "mldc = np.empty((mld.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    mldc[:, point_idx, :] = mld[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "np.savez(f'fesom_core2_fjra_mld1_m_{tmin}_{tmax}.npz', mldc=mldc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nflx_mld1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "ds_sbc = xr.open_mfdataset('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_budget_mld1_m_1980_2023_0.25.nc')\n",
    "ds_sbc['lon'] = (ds_sbc['lon'] + 360) % 360\n",
    "ds_sbc = ds_sbc.sortby('lon').sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "ds_mld = xr.open_mfdataset('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-budget/analysis/fesom/fesom_core2_fjra_oce2d_m_1980_2023_0.25.nc')\n",
    "ds_mld['lon'] = (ds_mld['lon'] + 360) % 360\n",
    "ds_mld = ds_mld.sortby('lon').sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "# nflx FIRST (keeps time)\n",
    "nflx = ds_sbc['heat_sbc'] * (-ds_mld['MLD1']) * 4.2e6\n",
    "\n",
    "nflux= nflx.groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "nfluxc = np.empty((nflux.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    nfluxc[:, point_idx, :] = nflux[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "np.savez(f'fesom_core2_fjra_nflux_mld1_m_{tmin}_{tmax}.npz', nfluxc=nfluxc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fesom-core2-fera5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_budget core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_budget_mld1_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "advx=ds['heat_advx'].groupby('time.month').mean(dim='time').values\n",
    "advy=ds['heat_advy'].groupby('time.month').mean(dim='time').values\n",
    "advz=ds['heat_advz'].groupby('time.month').mean(dim='time').values\n",
    "diffv=ds['heat_diffv'].groupby('time.month').mean(dim='time').values\n",
    "sbc=ds['heat_sbc'].groupby('time.month').mean(dim='time').values\n",
    "tdc=ds['heat_tdc'].groupby('time.month').mean(dim='time').values\n",
    "\n",
    "# also calculate the std and save it\n",
    "advx_std=ds['heat_advx'].groupby('time.month').std(dim='time').values\n",
    "advy_std=ds['heat_advy'].groupby('time.month').std(dim='time').values\n",
    "advz_std=ds['heat_advz'].groupby('time.month').std(dim='time').values\n",
    "diffv_std=ds['heat_diffv'].groupby('time.month').std(dim='time').values\n",
    "sbc_std=ds['heat_sbc'].groupby('time.month').std(dim='time').values\n",
    "tdc_std=ds['heat_tdc'].groupby('time.month').std(dim='time').values\n",
    "\n",
    "n = 16  # coast band + ocean band\n",
    "\n",
    "advx_c = np.empty((advx.shape[0], len(coast['lat']), n))\n",
    "advy_c = np.empty((advy.shape[0], len(coast['lat']), n))\n",
    "advz_c = np.empty((advz.shape[0], len(coast['lat']), n))\n",
    "diffv_c = np.empty((diffv.shape[0], len(coast['lat']), n))\n",
    "sbc_c = np.empty((sbc.shape[0], len(coast['lat']), n))\n",
    "tdc_c = np.empty((tdc.shape[0], len(coast['lat']), n))\n",
    "\n",
    "advx_c_std = np.empty((advx_std.shape[0], len(coast['lat']), n))\n",
    "advy_c_std = np.empty((advy_std.shape[0], len(coast['lat']), n))\n",
    "advz_c_std = np.empty((advz_std.shape[0], len(coast['lat']), n))\n",
    "diffv_c_std = np.empty((diffv_std.shape[0], len(coast['lat']), n))\n",
    "sbc_c_std = np.empty((sbc_std.shape[0], len(coast['lat']), n))\n",
    "tdc_c_std = np.empty((tdc_std.shape[0], len(coast['lat']), n))\n",
    "\n",
    "lono = np.empty((len(coast['lat']), n))\n",
    "lato = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    advx_c[:, point_idx, :] = advx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c[:, point_idx, :] = advy[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c[:, point_idx, :] = advz[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c[:, point_idx, :] = diffv[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c[:, point_idx, :] = sbc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c[:, point_idx, :] = tdc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advx_c_std[:, point_idx, :] = advx_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c_std[:, point_idx, :] = advy_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c_std[:, point_idx, :] = advz_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c_std[:, point_idx, :] = diffv_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c_std[:, point_idx, :] = sbc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c_std[:, point_idx, :] = tdc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lono[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    lato[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "np.savez(f'heat_budget_mld1_fera5_{tmin}_{tmax}.npz',\n",
    "         advx_c=advx_c, advy_c=advy_c, advz_c=advz_c,\n",
    "         diffv_c=diffv_c, sbc_c=sbc_c, tdc_c=tdc_c,\n",
    "         advx_c_std=advx_c_std, advy_c_std=advy_c_std, advz_c_std=advz_c_std,\n",
    "         diffv_c_std=diffv_c_std, sbc_c_std=sbc_c_std, tdc_c_std=tdc_c_std,\n",
    "         lono=lono, lato=lato)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_oce2d_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fera5_sstu_m_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_forcing_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "n = 8\n",
    "u = ds['tx_sur'].groupby('time.month').mean(dim='time').values\n",
    "v = ds['ty_sur'].groupby('time.month').mean(dim='time').values\n",
    "curl = ds['curl_surf'].groupby('time.month').mean(dim='time').values\n",
    "\n",
    "uc = np.empty((u.shape[0],len(coast['lat']), n))\n",
    "vc = np.empty((v.shape[0],len(coast['lat']), n))\n",
    "curlc = np.empty((curl.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    uc[:, point_idx, :] = u[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    vc[:, point_idx, :] = v[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    curlc[:, point_idx, :] = curl[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "# alongshore wind\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "    \n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    x = delta_lon * np.cos((lat1_rad + lat2_rad) / 2)\n",
    "    y = delta_lat\n",
    "    \n",
    "    bearing_rad = np.arctan2(y, x)\n",
    "    bearing_deg = np.rad2deg(bearing_rad)\n",
    "    bearing_deg = (bearing_deg + 360) % 360\n",
    "    \n",
    "    return bearing_deg\n",
    "\n",
    "point_num = len(coast['lat'])\n",
    "coast_orientation = np.empty(point_num)\n",
    "\n",
    "for i in range(point_num):\n",
    "    if i < point_num - 1:\n",
    "        lat1 = coast['lat'][i]\n",
    "        lon1 = coast['lon'][i]\n",
    "        lat2 = coast['lat'][i+1]\n",
    "        lon2 = coast['lon'][i+1]\n",
    "    else:\n",
    "        lat1 = coast['lat'][i-1]\n",
    "        lon1 = coast['lon'][i-1]\n",
    "        lat2 = coast['lat'][i]\n",
    "        lon2 = coast['lon'][i]\n",
    "    \n",
    "    bearing = calculate_bearing(lat1, lon1, lat2, lon2)\n",
    "    coast_orientation[i] = bearing\n",
    "\n",
    "coast_orientation_rad = np.deg2rad(coast_orientation)\n",
    "u_alongshore = np.cos(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "v_alongshore = np.sin(coast_orientation_rad).reshape(1, point_num, 1)\n",
    "wind_alongshore = uc * u_alongshore + vc * v_alongshore\n",
    "\n",
    "# Define the haversine function\n",
    "coast_lon = np.array(coast['lon'])  # Shape: (100,)\n",
    "coast_lat = np.array(coast['lat'])  # Shape: (100,)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  \n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad = np.deg2rad(lat1)\n",
    "    lon1_rad = np.deg2rad(lon1)\n",
    "    lat2_rad = np.deg2rad(lat2)\n",
    "    lon2_rad = np.deg2rad(lon2)\n",
    "\n",
    "    # Compute differences\n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(delta_lat / 2.0) ** 2 + \\\n",
    "        np.cos(lat1_rad) * np.cos(lat2_rad) * \\\n",
    "        np.sin(delta_lon / 2.0) ** 2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Expand coast_lon and coast_lat for broadcasting\n",
    "coast_lon_expanded = coast_lon[:, np.newaxis]  # Shape: (100, 1)\n",
    "coast_lat_expanded = coast_lat[:, np.newaxis]  # Shape: (100, 1)\n",
    "\n",
    "# Compute distances\n",
    "distances = haversine(coast_lat_expanded, coast_lon_expanded, latc, lonc)  # Shape: (100, 8)\n",
    "\n",
    "# Constants\n",
    "rhoa = 1.22  # air density (kg/m^3)\n",
    "cd = 0.0013  # drag coefficient\n",
    "rho = 1025  # water density (kg/m^3)\n",
    "omega = 7.2921e-5  # Earth's rotation rate (rad/s)\n",
    "\n",
    "f = 2 * omega * np.sin(latc* np.pi / 180)\n",
    "\n",
    "# Calculate magnitude of horizontal velocity\n",
    "windspeed = np.sqrt(uc**2 + vc**2)\n",
    "\n",
    "# Ekman transport calculation\n",
    "etransport = -wind_alongshore / (rho * f * distances)\n",
    "# wind_alongshore_mean = wind_alongshore[:, :, 0]\n",
    "# mwind_alongshore_mean_filled = np.broadcast_to(wind_alongshore_mean[:, :, np.newaxis], wind_alongshore.shape)\n",
    "# etransport = -wind_alongshore_mean_filled / (rho * f * distances)\n",
    "\n",
    "epumping = np.zeros_like(uc)  # Ensure it has the right shape and is mutable\n",
    "dy = 111000.0 * (lat[1] - lat[0])  # scalar\n",
    "dv_dx = np.zeros_like(uc)\n",
    "for j in range(lat.shape[0]):\n",
    "    x_j = 111000.0 * np.cos(np.radians(lat[j])) * (lon[1] - lon[0]) \n",
    "    epumping[:,j,:] = 1 / (rho ) * (np.gradient(vc[:, j, :]/ f[j], x_j, axis=-1) - np.gradient(uc[:,j,:]/ f[j], dy, axis=1))\n",
    "\n",
    "np.savez(f'fesom_core2_fera5_ekman_m_{tmin}_{tmax}.npz', windspeed=windspeed, etransport=etransport, epumping=epumping, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_forcing_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "fh=-ds['fh'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "fhc = np.empty((fh.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    fhc[:, point_idx, :] = fh[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "fh=fhc[:,:,8:]-fhc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fera5_fh_m_{tmin}_{tmax}.npz', fh=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w_mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_w_mld1_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "w=ds['w_mld'].groupby('time.month').mean(dim='time').values\n",
    "n = 8\n",
    "wc = np.empty((w.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    wc[:, point_idx, :] = w[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "np.savez(f'fesom_core2_fera5_w_mld1_m_{tmin}_{tmax}.npz', wc=wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fesom-core2-fcore2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_budget core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-core2-budget/analysis/fesom/fesom_core2_fcore2_budget_mld1_m_1980_2009_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "\n",
    "advx=ds['heat_advx'].groupby('time.month').mean(dim='time').values\n",
    "advy=ds['heat_advy'].groupby('time.month').mean(dim='time').values\n",
    "advz=ds['heat_advz'].groupby('time.month').mean(dim='time').values\n",
    "diffv=ds['heat_diffv'].groupby('time.month').mean(dim='time').values\n",
    "sbc=ds['heat_sbc'].groupby('time.month').mean(dim='time').values\n",
    "tdc=ds['heat_tdc'].groupby('time.month').mean(dim='time').values\n",
    "\n",
    "# also calculate the std and save it\n",
    "advx_std=ds['heat_advx'].groupby('time.month').std(dim='time').values\n",
    "advy_std=ds['heat_advy'].groupby('time.month').std(dim='time').values\n",
    "advz_std=ds['heat_advz'].groupby('time.month').std(dim='time').values\n",
    "diffv_std=ds['heat_diffv'].groupby('time.month').std(dim='time').values\n",
    "sbc_std=ds['heat_sbc'].groupby('time.month').std(dim='time').values\n",
    "tdc_std=ds['heat_tdc'].groupby('time.month').std(dim='time').values\n",
    "\n",
    "n = 16  # coast band + ocean band\n",
    "\n",
    "advx_c = np.empty((advx.shape[0], len(coast['lat']), n))\n",
    "advy_c = np.empty((advy.shape[0], len(coast['lat']), n))\n",
    "advz_c = np.empty((advz.shape[0], len(coast['lat']), n))\n",
    "diffv_c = np.empty((diffv.shape[0], len(coast['lat']), n))\n",
    "sbc_c = np.empty((sbc.shape[0], len(coast['lat']), n))\n",
    "tdc_c = np.empty((tdc.shape[0], len(coast['lat']), n))\n",
    "\n",
    "advx_c_std = np.empty((advx_std.shape[0], len(coast['lat']), n))\n",
    "advy_c_std = np.empty((advy_std.shape[0], len(coast['lat']), n))\n",
    "advz_c_std = np.empty((advz_std.shape[0], len(coast['lat']), n))\n",
    "diffv_c_std = np.empty((diffv_std.shape[0], len(coast['lat']), n))\n",
    "sbc_c_std = np.empty((sbc_std.shape[0], len(coast['lat']), n))\n",
    "tdc_c_std = np.empty((tdc_std.shape[0], len(coast['lat']), n))\n",
    "\n",
    "lono = np.empty((len(coast['lat']), n))\n",
    "lato = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    advx_c[:, point_idx, :] = advx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c[:, point_idx, :] = advy[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c[:, point_idx, :] = advz[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c[:, point_idx, :] = diffv[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c[:, point_idx, :] = sbc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c[:, point_idx, :] = tdc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advx_c_std[:, point_idx, :] = advx_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c_std[:, point_idx, :] = advy_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c_std[:, point_idx, :] = advz_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c_std[:, point_idx, :] = diffv_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c_std[:, point_idx, :] = sbc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c_std[:, point_idx, :] = tdc_std[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lono[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    lato[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "np.savez(f'heat_budget_mld1_fcore2_{tmin}_2009.npz',\n",
    "         advx_c=advx_c, advy_c=advy_c, advz_c=advz_c,\n",
    "         diffv_c=diffv_c, sbc_c=sbc_c, tdc_c=tdc_c,\n",
    "         advx_c_std=advx_c_std, advy_c_std=advy_c_std, advz_c_std=advz_c_std,\n",
    "         diffv_c_std=diffv_c_std, sbc_c_std=sbc_c_std, tdc_c_std=tdc_c_std,\n",
    "         lono=lono, lato=lato)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advx_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fcore2\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-core2-budget/analysis/fesom/fesom_core2_fcore2_oce2d_m_1980_2009_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fcore2_sstu_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fera5\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/core2-fera5-budget/analysis/fesom/fesom_core2_fera5_oce2d_m_1980_2022_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_core2_fera5_sstu_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import cm\n",
    "\n",
    "[xmin,xmax,ymin,ymax]=[270,290,-16,-6]\n",
    "[tmin,tmax]=[\"1993\",\"2022\"] \n",
    "        \n",
    "# heat_budget core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_home/geomar/smomw639/FESOM/analysis/heat_budget_seasonal.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "\n",
    "lon=ds['lon'].sel(lon=slice(xmin, xmax)).values\n",
    "lat=ds['lat'].sel(lat=slice(ymin,ymax)).values\n",
    "time=ds['time'].sel(time=slice(tmin,tmax))\n",
    "\n",
    "sst0=ds['advx'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax)).isel(time=0).values\n",
    "coast = {'lat': [], 'lon': []}\n",
    "    \n",
    "for i, lat_val in enumerate(lat):\n",
    "    for j, lon_val in enumerate(lon):            \n",
    "        if np.isnan(sst0[i, j]):\n",
    "            coast['lat'].append(lat_val.item())\n",
    "            coast['lon'].append(lon_val.item())\n",
    "            break  \n",
    "\n",
    "advx=ds['advx'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "advy=ds['advy'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "advz=ds['advz'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "diffv=ds['diffv'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "sbc=ds['sbc'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "tdc=ds['tdc'].sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax))\n",
    "\n",
    "n = 24  # coast band + ocean band\n",
    "\n",
    "advx_c = np.empty((advx.shape[0], len(coast['lat']), n))\n",
    "advy_c = np.empty((advy.shape[0], len(coast['lat']), n))\n",
    "advz_c = np.empty((advz.shape[0], len(coast['lat']), n))\n",
    "diffv_c = np.empty((diffv.shape[0], len(coast['lat']), n))\n",
    "sbc_c = np.empty((sbc.shape[0], len(coast['lat']), n))\n",
    "tdc_c = np.empty((tdc.shape[0], len(coast['lat']), n))\n",
    "\n",
    "lono = np.empty((len(coast['lat']), n))\n",
    "lato = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    advx_c[:, point_idx, :] = advx[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advy_c[:, point_idx, :] = advy[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    advz_c[:, point_idx, :] = advz[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    diffv_c[:, point_idx, :] = diffv[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    sbc_c[:, point_idx, :] = sbc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    tdc_c[:, point_idx, :] = tdc[:, lat_idx, int(lon_idx-n) : int(lon_idx)]\n",
    "    lono[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    lato[point_idx, :] = lat[lat_idx]\n",
    "\n",
    "np.savez(f'heat_budget_peru_fjra_{tmin}_{tmax}.npz',\n",
    "         advx_c=advx_c, advy_c=advy_c, advz_c=advz_c,\n",
    "         diffv_c=diffv_c, sbc_c=sbc_c, tdc_c=tdc_c,\n",
    "         lono=lono, lato=lato)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# markus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core2-fjra\n",
    "file_path = os.path.expandvars('/gxfs_work/geomar/smomw639/runtime/fesom-2.6/core2/markus/analysis/fesom/fesom_core2_fjra_oce2d_m_1980_2023_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_core2_markus_sstu_m_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fesom-tropotest-fjra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expandvars('/gxfs_home/geomar/smomw639/Paper1/fesom_tropotest_fjra_oce2d_m_1993_2009_0.25.nc')\n",
    "ds = xr.open_dataset(\n",
    "    file_path\n",
    ")\n",
    "ds['lon'] = (ds['lon'] + 360) % 360\n",
    "ds=ds.sortby('lon')\n",
    "ds=ds.sel(lon=slice(xmin,xmax), lat=slice(ymin,ymax), time=slice(tmin,tmax))\n",
    "# calculate climological mean of sst\n",
    "sst=ds['sst'].groupby('time.month').mean(dim='time').values\n",
    "n = 16\n",
    "sstc = np.empty((sst.shape[0],len(coast['lat']), n))\n",
    "lonc = np.empty((len(coast['lat']), n))\n",
    "latc = np.empty((len(coast['lat']), n))\n",
    "\n",
    "for point_idx, (lat_val, lon_val) in enumerate(zip(coast['lat'], coast['lon'])):\n",
    "    lat_idx = np.abs(lat - lat_val).argmin()\n",
    "    lon_idx = np.abs(lon - lon_val).argmin()\n",
    "    sstc[:, point_idx, :] = sst[:, lat_idx, int(lon_idx-n) : int(lon_idx)]      # costal band\n",
    "    lonc[point_idx, :] = lon[int(lon_idx-n) : int(lon_idx)]\n",
    "    latc[point_idx, :] = lat[lat_idx]\n",
    "sstu=sstc[:,:,8:]-sstc[:,:,:8]\n",
    "np.savez(f'fesom_tropotest_fjra_sstu_m_{tmin}_{tmax}.npz', lon=lon, lat=lat, sstu=sstu, sstc=sstc, coast=coast, lonc=lonc, latc=latc, time=time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
